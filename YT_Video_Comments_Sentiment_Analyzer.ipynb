{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwl20yRMfivm"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain\n",
        "# pip install google-api-python-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk-BTSWILDrx"
      },
      "outputs": [],
      "source": [
        "import googleapiclient.discovery\n",
        "import googleapiclient.errors,re\n",
        "\n",
        "api_service_name = \"youtube\"\n",
        "api_version = \"v3\"\n",
        "DEVELOPER_KEY = \"Developer-API-Key\"\n",
        "\n",
        "youtube = googleapiclient.discovery.build(\n",
        "    api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
        "\n",
        "def extract_video_id(url):\n",
        "    # Regular expression to find the video ID\n",
        "    video_id = None\n",
        "    patterns = [\n",
        "        r'^https?://(?:youtu\\.be/|www\\.youtube\\.com(?:/embed/|/v/|/watch\\?v=|/watch\\?.+&v=))([\\w-]{11})(?:$|&|\\?)',\n",
        "        r'^https?://(?:www\\.youtube-nocookie\\.com/v/|www\\.youtube\\.com/v/|youtu\\.be/)([\\w-]{11})']\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, url.strip())\n",
        "        if match:\n",
        "            video_id = match.group(1)\n",
        "            break\n",
        "\n",
        "    return video_id\n",
        "\n",
        "comments = []\n",
        "\n",
        "# Function to fetch comments\n",
        "def fetch_comments(youtube, video_id):\n",
        "    video_id = extract_video_id(video_id)\n",
        "    if video_id:\n",
        "        next_page_token = None\n",
        "        while True:\n",
        "            request = youtube.commentThreads().list(\n",
        "                part=\"snippet\",\n",
        "                videoId=video_id,\n",
        "                textFormat=\"plainText\",\n",
        "                maxResults=100,\n",
        "                pageToken=next_page_token)\n",
        "            response = request.execute()\n",
        "\n",
        "            for item in response['items']:\n",
        "                comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
        "                comments.append(comment)\n",
        "\n",
        "            next_page_token = response.get('nextPageToken')\n",
        "            if not next_page_token:\n",
        "                break\n",
        "    else:\n",
        "        print(\"Invalid URL.\")\n",
        "\n",
        "video_url = \"htsdftps://youtu.be/UrsmFxEIp5k?si=8tC3sewys-diVnEa\"\n",
        "fetch_comments(youtube, video_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpuoHClSLK4S",
        "outputId": "1da99226-7116-42d1-d7d7-5cd3cf4e15dc"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\",truncation=True)\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "def get_sentiment(comment):\n",
        "    res = pipe(comment)\n",
        "    return {comment:res[0]['label']}\n",
        "\n",
        "def custom_output_parser(data):\n",
        "    comments_with_sentiments = {}\n",
        "    for item in data:\n",
        "      for comment,sentiment in item.items():\n",
        "        comments_with_sentiments[comment] = sentiment\n",
        "    return comments_with_sentiments\n",
        "\n",
        "chain = RunnablePassthrough() | get_sentiment\n",
        "\n",
        "res = custom_output_parser(await chain.abatch(comments))\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "l6gv-52AXDny",
        "outputId": "9c02631d-8172-4713-e5ff-a09ec7a36be8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(list(res.items()),columns=[\"comments\",\"sentiments\"])\n",
        "\n",
        "print(df[\"sentiments\"].value_counts())\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.bar(df[\"sentiments\"].value_counts().index,df[\"sentiments\"].value_counts().values)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
